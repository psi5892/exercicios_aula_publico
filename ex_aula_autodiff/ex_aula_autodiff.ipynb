{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26fxjoVADscQ"
   },
   "source": [
    "Para abrir o notebook no Google Colab, altere o domínio `github.com` para `githubtocolab.com`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Para praticar programação, é importante que você erre, leia as mensagens de erro e tente corrigí-los.\n",
    "    \n",
    "Dessa forma, no Google Colab, é importante que você DESATIVE OS RECURSOS DE AUTOCOMPLETAR:\n",
    "\n",
    "- Menu Ferramentas -> Configurações\n",
    "- Na janela que é aberta:\n",
    "  - Seção Editor -> Desativar \"Mostrar sugestões de preenchimento de código com base no contexto\"\n",
    "  - Seção Assistência de IA -> Desabilitar itens\n",
    "\n",
    "Na versão em inglês:\n",
    "\n",
    "- Menu Tools -> Settings\n",
    "- Na janela que é aberta:\n",
    "  - Seção Editor -> Desativar \"Show context-powered code completions\"\n",
    "  - Seção AI Assistance -> Desabilitar itens\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c04thLl8Dzh4"
   },
   "source": [
    "# PSI5892 - Aula de Exercícios\n",
    "\n",
    "# Diferenciação automática\n",
    "\n",
    "Neste exercício vamos implementar um tipo que utiliza diferenciação automática e vamos utilizá-lo para implementaro algoritmo LMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VfzscWYDgio",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1\n",
    "\n",
    "Com base no tipo dual que vimos na aula, vamos implementar as operações de subtração e divisão, para compor uma versão capaz de trabalhar com as quatro operações aritméticas básicas.\n",
    "\n",
    "A subtração é implementada por meio do método ``__sub__`` e a multiplicação por meio do ``__mul__``. Lembre de incluir os métodos ``__rsub__`` e ``__rmul__`` para que o tipo dual funcione no caso de fazer uma operação do tipo ``x - D`` ou ``x * D``, com ``x`` sendo um objeto que não é do tipo dual e ``D`` sendo um objeto do tipo dual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D:\n",
    "    def __init__(self, x, xd):\n",
    "        self.x = x\n",
    "        self.xd = xd\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, D):\n",
    "            other = D(other, 0)\n",
    "        return D(self.x + other.x, self.xd + other.xd)\n",
    "\n",
    "    def __radd__(self, lhs):\n",
    "        return self + lhs\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        if not isinstance(other, D):\n",
    "            other = D(other, 0)\n",
    "        return D(self.x / other.x, (self.xd * other.x - self.x * other.xd) / (other.x**2))\n",
    "\n",
    "    def __rtruediv__(self, lhs):\n",
    "        if not isinstance(lhs, D):\n",
    "            lhs = D(lhs, 0)            \n",
    "        return lhs / self\n",
    "\n",
    "    #############\n",
    "    # Complete o código\n",
    "\n",
    "    # def __sub__(self, other):\n",
    "        \n",
    "\n",
    "    # def __rsub__(self, lhs):\n",
    "        \n",
    "\n",
    "    # def __mul__(self, other):\n",
    "        \n",
    "\n",
    "    # def __rmul__(self, lhs):\n",
    "        \n",
    "\n",
    "    #############\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.x} + {self.xd}ϵ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora teste o tipo ``D`` com operações de subtração e divisão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = 7\n",
    "x_1_D = D(x_1, 2)\n",
    "\n",
    "x_2 = 5\n",
    "x_2_D = D(x_2, 1)\n",
    "\n",
    "y = x_1_D - x_2_D # deve resultar em D(2, 1)\n",
    "assert y.x == 2 and y.xd == 1\n",
    "\n",
    "y = x_1_D - x_2 # deve resultar em D(2, 2)\n",
    "assert y.x == 2 and y.xd == 2\n",
    "\n",
    "y = x_1 - x_2_D # deve resultar em D(2, -1)\n",
    "assert y.x == 2 and y.xd == -1\n",
    "\n",
    "y = x_1_D * x_2_D # deve resultar em D(35, 17)\n",
    "assert y.x == 35 and y.xd == 17\n",
    "\n",
    "y = x_1_D * x_2 # deve resultar em D(35, 10)\n",
    "assert y.x == 35 and y.xd == 10\n",
    "\n",
    "y = x_1 * x_2_D # deve resultar em D(35, 7)\n",
    "assert y.x == 35 and y.xd == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2\n",
    "\n",
    "Agora, vamos implementar o algoritmo LMS usando autodiff. Nesse caso, vale notar que vamos precisar calcular o quadrado do erro e, por isso, precisamos da operação de potenciação, além das operações aritméticas básicas.\n",
    "\n",
    "Complemente a classe implementada no exercício 1 com o método ``__pow__`` que implementa a operação de potenciação, efetuada quando utilizamos o operador ``**``. Note que nesse caso, precisamos apenas da operação de potenciação do tipo ``x**k``, em ``x`` é um objeto dual e ``k`` é uma constante. Dessa forma, não há a necessidade de implementar o método ``__rpow__``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Complete o código\n",
    "\n",
    "\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora teste o tipo ``D`` com a operação de potenciação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2\n",
    "x_D = D(x, 2)\n",
    "\n",
    "k = 3\n",
    "\n",
    "y = x_D ** k # deve resultar em D(8, 24)\n",
    "assert y.x == 8 and y.xd == 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos trabalhar com o LMS no contexto do problema das meias luas. Para isso, vamos iniciar gerando dados para treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meias_luas(NA, NB, r1, r2, r3):\n",
    "    \"\"\"\n",
    "    dados = meias_luas(NA,NB,r1,r2,r3)\n",
    "    NA: número de pontos da região A\n",
    "    NB: número de pontos da região B\n",
    "    r1, r2 e r3: dados das meias-luas\n",
    "    \"\"\"\n",
    "\n",
    "    Nt = NA + NB  # total de dados de treinamento\n",
    "\n",
    "    # dados das meia luas\n",
    "    rmin = r1 - r3 / 2\n",
    "    rmax = r1 + r3 / 2\n",
    "\n",
    "    # Pontos da Região A\n",
    "    a = np.pi * np.random.rand(NA, 1)\n",
    "    rxy = np.random.uniform(rmin, rmax, (NA, 1))\n",
    "    xA = rxy * np.cos(a)\n",
    "    yA = rxy * np.sin(a)\n",
    "    dA = np.ones((NA, 1))\n",
    "    pontosA = np.hstack((xA, yA, dA))\n",
    "\n",
    "    # Pontos da Região B\n",
    "    a = np.pi * np.random.rand(NB, 1)\n",
    "    rxy = np.random.uniform(rmin, rmax, (NB, 1))\n",
    "    xB = rxy * np.cos(a) + r1\n",
    "    yB = -rxy * np.sin(a) - r2\n",
    "    dB = -np.ones((NB, 1))\n",
    "    pontosB = np.hstack((xB, yB, dB))\n",
    "\n",
    "    # Concatenando e embaralhando os dados\n",
    "    dados = np.vstack((pontosA, pontosB))\n",
    "    np.random.shuffle(dados)\n",
    "\n",
    "    # Figura para mostrar os dados de treino\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(xA, yA, \".b\")\n",
    "    ax1.plot(xB, yB, \".r\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.grid(axis=\"x\", color=\"0.5\")\n",
    "    plt.grid(axis=\"y\", color=\"0.5\")\n",
    "\n",
    "    return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NA = 5000\n",
    "NB = 5000\n",
    "Nt = NA + NB  # número de dados de treinamento\n",
    "r1 = 10\n",
    "r3 = 6\n",
    "r2 = 4\n",
    "\n",
    "dados_treino = meias_luas(NA, NB, r1, r2, r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizando os dados para entrada do LMS\n",
    "xtreino = dados_treino[:, [0, 1]]  # sinal de entrada\n",
    "dtreino = dados_treino[:, [2]]  # sinal desejado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando os dados ``x`` e ``d``, implemente o algoritmo LMS usando autodiff. Para isso, toda a computação deve ser implementada usando tipos duais para que os gradientes sejam calculados automaticamente. Leve em conta as seguintes considerações:\n",
    "\n",
    "- O tipo dual que implementamos é capaz de lidar apenas com escalares. Na prática, é necessário o uso de tipos vetoriais capazes de obter os gradientes de forma automática. Para este exercício, vamos trabalhar com o tipo escalar e fixar o número de coeficientes adaptados pelo LMS em 3 (``M=2`` acrescido de um coeficiente para o bias)\n",
    "- Lembre-se de que estamos utilizando o modo progressivo para o cálculo dos gradientes. Dessa forma, será necessário executar o cálculo da saída por 3 vezes consecutivas para obter o gradiente para os 2 pesoa e bias, respectivamente.\n",
    "- Para facilitar a implementação, considere o modo estocástico, em que os pesos são adaptados a cada exemplo de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LMS com autodiff\n",
    "M fixo e igual a 2 - para evitar implementar vetores de dimensão arbitrária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMS_FILTER_estocastico_autodiff(x, d, eta, Nt):\n",
    "    \"\"\"\n",
    "    W = LMS_FILTER_estocastico(x, d, eta, Nt)\n",
    "    x: sinal de entrada\n",
    "    d: sinal desejado\n",
    "    eta: passo de adaptação\n",
    "    Nt: número de dados de treinamento\n",
    "    \"\"\"\n",
    "    M = 2\n",
    "    # inserimos uma coluna de uns ao vetor de entrada para levar em conta o bias\n",
    "    x = np.hstack((np.ones((Nt, 1)), x))\n",
    "\n",
    "    W = np.zeros((Nt + 1, M + 1))\n",
    "\n",
    "    for i in range(Nt):\n",
    "        pass\n",
    "        # Inicie com o bloco de código para adaptação do bias\n",
    "\n",
    "        # Crie uma variável dual para cada elemento a respeito do qual desejamos calcular o gradiente da função custo\n",
    "        # Indique a parte dual igual a 1 para o bias\n",
    "        #############\n",
    "        # Complete o código\n",
    "        # B_D = \n",
    "        # W0_D = \n",
    "        # W1_D = \n",
    "        #############\n",
    "\n",
    "        # Calcule a saída, o erro, e o valor da da função custo do MSE\n",
    "        # Tome cuidado para que todas as variáveis alocadas dos dados de treino sejam tratadas como\n",
    "        # tipos básicos do Python (e não do numpy). Para tanto, use float(<valor escalar do tipo numpy>)\n",
    "        #############\n",
    "        # Complete o código\n",
    "        # y = \n",
    "        # e = \n",
    "        # J = \n",
    "        #############\n",
    "\n",
    "        # Implemente a atualização do bias usando o gradiente calculado automaticamente\n",
    "        # Como a variável dual do bias foi criada com a parte dual igual a 1, J.xd vai conter\n",
    "        # o gradiente de J em relação ao bias\n",
    "        # Lembre-se que é necessário dividir o passo por 2 para chegar ao mesmo comportamento\n",
    "        # do algoritmo calculado manualmente\n",
    "        #############\n",
    "        # Complete o código        \n",
    "        # B_D = \n",
    "        #############\n",
    "        \n",
    "        # Por fim, vamos guardar os valores do bias ao longo das iterações em W\n",
    "        # W[i + 1, 0] = B_D.x\n",
    "\n",
    "        # Repita as operações para o peso W0\n",
    "        #############\n",
    "        # Complete o código        \n",
    "\n",
    "        #############\n",
    "        \n",
    "        # Repita as operações para o peso W1\n",
    "        #############\n",
    "        # Complete o código        \n",
    "\n",
    "        #############\n",
    "        \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando o treinamento com a função implementada e plotando as curvas de convergência dos coeficientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-3  # passo de adaptação do LMS\n",
    "We = LMS_FILTER_estocastico_autodiff(xtreino, dtreino, eta, Nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# Mostra os pesos ao longo do treinamento\n",
    "plt.plot(We, \"k\", label=\"LMS\")\n",
    "plt.xlabel(\"iterações\")\n",
    "plt.ylabel(\"pesos\")\n",
    "plt.grid(axis=\"x\", color=\"0.5\")\n",
    "plt.grid(axis=\"y\", color=\"0.5\")\n",
    "plt.title(\n",
    "    \"Pesos do LMS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vamos considerar o valor dos coeficientes na última iteração como sendo o modelo e testá-lo com dados de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de teste\n",
    "NAt = 1000\n",
    "NBt = 1000\n",
    "Nteste = NAt + NBt\n",
    "\n",
    "dados_teste = meias_luas(NAt, NBt, r1, r2, r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We_last = We[[-1], :].T\n",
    "\n",
    "# Inserindo 1's no vetor de entrada\n",
    "xteste = dados_teste[:, 0:2]  # sinal de entrada\n",
    "b = np.ones((Nteste, 1))\n",
    "xteste = np.hstack((b, xteste))\n",
    "dteste = dados_teste[:, 2].reshape(-1, 1)  # sinal desejado\n",
    "yteste = xteste @ We_last  # saída do filtro de Wiener considerando os dados de teste\n",
    "\n",
    "# Gera a curva de separação das duas regiões\n",
    "# Dados da curva de separação\n",
    "Nsep = 100\n",
    "x1S = np.linspace(-15, 25, Nsep).reshape(-1, 1)\n",
    "x2S = np.linspace(-20, 15, Nsep).reshape(-1, 1)\n",
    "\n",
    "# Gera pontos da grade\n",
    "xx1S, xx2S = np.meshgrid(x1S, x2S)\n",
    "xx1S = xx1S.reshape(-1, 1)\n",
    "xx2S = xx2S.reshape(-1, 1)\n",
    "\n",
    "# Gera array x \n",
    "xgrid = np.hstack((xx1S, xx2S))\n",
    "Ngrid = len(xgrid)\n",
    "b = np.ones((Ngrid, 1))\n",
    "xgrid = np.hstack((b, xgrid))\n",
    "\n",
    "# Calcula saída para cada ponto da grade\n",
    "ygrid = np.sign(xgrid @ We_last)\n",
    "\n",
    "# Plota os pontos principais\n",
    "fig, ax2 = plt.subplots()\n",
    "for i in range(Nteste):\n",
    "    if dteste[i] == 1:\n",
    "        ax2.plot(xteste[i, 1], xteste[i, 2], \".b\")\n",
    "    else:\n",
    "        ax2.plot(xteste[i, 1], xteste[i, 2], \".r\")\n",
    "\n",
    "# Plota pontos da grade com saída -1 (usa transparência alpha)        \n",
    "l0 = np.where(ygrid == -1)[0]\n",
    "ax2.plot(xgrid[l0, 1], xgrid[l0, 2], \"r.\", alpha=0.1)\n",
    "\n",
    "# Plota pontos da grade com saída 1 (usa transparência alpha)\n",
    "l1 = np.where(ygrid == 1)[0]\n",
    "ax2.plot(xgrid[l1, 1], xgrid[l1, 2], \"b.\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3\n",
    "\n",
    "Agora vamos implementar a regressão logística usando o MSE e função $\\rm tanh$, com base no algoritmo implementado no Exercício 2. Para isso, precisamos da função tanh, que pode ser escrita como\n",
    "\n",
    "$${\\rm tanh} = \\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}.$$\n",
    "\n",
    "Dessa forma, a partir de um tipo dual capaz de realizar operações do tipo ``k**x``, com ``k`` constante e ``x`` dual, é possível implementar uma função ``tanh`` que funcione com variáveis duais.\n",
    "\n",
    "Complemente a classe ``D`` implementada no exercício anterior com o método ``__rpow__`` que implementa a operação de potenciação à direita, para tratar de ``k**x``, com ``k`` constante e ``x`` dual. Utilize a função ``math.log`` para calcular o ${\\rm ln}$ e leve em conta que a derivada da função exponencial é dada por\n",
    "\n",
    "$$(k^{f(x)})' = k^{f(x)} \\cdot {\\rm ln}(k)f'(x).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Complete o código\n",
    "\n",
    "\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora teste o tipo ``D`` com a exponencial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3\n",
    "x_D = D(x, 2)\n",
    "\n",
    "k = 2\n",
    "\n",
    "y = k ** x_D # deve resultar em D(8, 8*ln(2)*2)\n",
    "assert y.x == 8 and y.xd == 8 * math.log(2)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o tipo ``D`` capaz de calcular a exponenciação, implemente a função tanh para lidar com tipos duais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Complete o código\n",
    "\n",
    "# def tanh(x):\n",
    "    # return \n",
    "#############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste a função tanh, lembrando que $({\\rm tanh(f(x))})' = (1 - tanh^2(f(x))) \\cdot f'(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3\n",
    "x_D = D(x, 2)\n",
    "\n",
    "y = tanh(x_D) # deve resultar em D(tanh(x), (1 - tanh(x)**2) * 2)\n",
    "\n",
    "np.testing.assert_array_almost_equal(y.x, np.tanh(x), decimal=6)\n",
    "np.testing.assert_array_almost_equal(y.xd, (1 - (np.tanh(x))**2)*2, decimal=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a função ``tanh`` implementada e com base na função para o LMS construída anteriormente, implemente o algoritmo LMS para a regressão logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMS_FILTER_estocastico_reglog_autodiff(x, d, eta, Nt):\n",
    "    \"\"\"\n",
    "    y,e,W = LMS_FILTER_estocastico(x,d,eta,M,Nt)\n",
    "    x: sinal de entrada\n",
    "    d: sinal desejado\n",
    "    eta: passo de adaptação\n",
    "    Nt: número de dados de treinamento\n",
    "    \"\"\"\n",
    "    M = 2\n",
    "    # inserimos uma coluna de uns ao vetor de entrada para levar em conta o bias\n",
    "    x = np.hstack((np.ones((Nt, 1)), x))\n",
    "\n",
    "    W = np.zeros((Nt + 1, M + 1))\n",
    "\n",
    "    #############\n",
    "    # Complete o código\n",
    "\n",
    "\n",
    "    #############\n",
    "\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vamos testar o algoritmo como fizemos no exercício 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-3  # passo de adaptação do LMS\n",
    "We = LMS_FILTER_estocastico_reglog_autodiff(xtreino, dtreino, eta, Nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# Mostra os pesos ao longo do treinamento\n",
    "plt.plot(We, \"k\", label=\"LMS\")\n",
    "plt.xlabel(\"iterações\")\n",
    "plt.ylabel(\"pesos\")\n",
    "plt.grid(axis=\"x\", color=\"0.5\")\n",
    "plt.grid(axis=\"y\", color=\"0.5\")\n",
    "plt.title(\n",
    "    \"Pesos do LMS\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We_last = We[[-1], :].T\n",
    "\n",
    "# Inserindo 1's no vetor de entrada\n",
    "xteste = dados_teste[:, 0:2]  # sinal de entrada\n",
    "b = np.ones((Nteste, 1))\n",
    "xteste = np.hstack((b, xteste))\n",
    "dteste = dados_teste[:, 2].reshape(-1, 1)  # sinal desejado\n",
    "yteste = xteste @ We_last  # saída do filtro de Wiener considerando os dados de teste\n",
    "\n",
    "# Gera a curva de separação das duas regiões\n",
    "# Dados da curva de separação\n",
    "Nsep = 100\n",
    "x1S = np.linspace(-15, 25, Nsep).reshape(-1, 1)\n",
    "x2S = np.linspace(-20, 15, Nsep).reshape(-1, 1)\n",
    "\n",
    "# Gera pontos da grade\n",
    "xx1S, xx2S = np.meshgrid(x1S, x2S)\n",
    "xx1S = xx1S.reshape(-1, 1)\n",
    "xx2S = xx2S.reshape(-1, 1)\n",
    "\n",
    "# Gera array x \n",
    "xgrid = np.hstack((xx1S, xx2S))\n",
    "Ngrid = len(xgrid)\n",
    "b = np.ones((Ngrid, 1))\n",
    "xgrid = np.hstack((b, xgrid))\n",
    "\n",
    "# Calcula saída para cada ponto da grade\n",
    "ygrid = np.sign(xgrid @ We_last)\n",
    "\n",
    "# Plota os pontos principais\n",
    "fig, ax2 = plt.subplots()\n",
    "for i in range(Nteste):\n",
    "    if dteste[i] == 1:\n",
    "        ax2.plot(xteste[i, 1], xteste[i, 2], \".b\")\n",
    "    else:\n",
    "        ax2.plot(xteste[i, 1], xteste[i, 2], \".r\")\n",
    "\n",
    "# Plota pontos da grade com saída -1 (usa transparência alpha)        \n",
    "l0 = np.where(ygrid == -1)[0]\n",
    "ax2.plot(xgrid[l0, 1], xgrid[l0, 2], \"r.\", alpha=0.1)\n",
    "\n",
    "# Plota pontos da grade com saída 1 (usa transparência alpha)\n",
    "l1 = np.where(ygrid == 1)[0]\n",
    "ax2.plot(xgrid[l1, 1], xgrid[l1, 2], \"b.\", alpha=0.1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
