{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26fxjoVADscQ"
   },
   "source": [
    "Para abrir o notebook no Google Colab, altere o domínio `github.com` para `githubtocolab.com`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Para praticar programação, é importante que você erre, leia as mensagens de erro e tente corrigí-los.\n",
    "    \n",
    "Dessa forma, no Google Colab, é importante que você DESATIVE OS RECURSOS DE AUTOCOMPLETAR:\n",
    "\n",
    "- Menu Ferramentas -> Configurações\n",
    "- Na janela que é aberta:\n",
    "  - Seção Editor -> Desativar \"Mostrar sugestões de preenchimento de código com base no contexto\"\n",
    "  - Seção Assistência de IA -> Desabilitar itens\n",
    "\n",
    "Na versão em inglês:\n",
    "\n",
    "- Menu Tools -> Settings\n",
    "- Na janela que é aberta:\n",
    "  - Seção Editor -> Desativar \"Show context-powered code completions\"\n",
    "  - Seção AI Assistance -> Desabilitar itens\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c04thLl8Dzh4"
   },
   "source": [
    "# PSI5892 - Aula de Exercícios\n",
    "\n",
    "# MLP com PyTorch\n",
    "\n",
    "Neste exercício vamos treinar uma rede MLP usando o *framework* PyTorch, para a solução de um problema de classificação usando o banco de dados [Fashion MNIST](https://arxiv.org/abs/1708.07747), que contém 70000 imagens 28x28 de peças de vestuário distribuídas em 10 classes, divididas em um conjunto de treinamento com 60000 imagens e um de teste com 10000.\n",
    "\n",
    "Os dados estão disponíveis na biblioteca `torchvision` e os objetos `DataLoader` podem ser criados com:\n",
    "\n",
    "``` python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "dir_data = \"~/temp\"\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        dir_data,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(            \n",
    "            [transforms.ToTensor()]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=Nb,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        dir_data,\n",
    "        train=False,\n",
    "        transform=transforms.Compose(            \n",
    "            [transforms.ToTensor()]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=Nb_test,\n",
    "    shuffle=True,\n",
    ")\n",
    "```\n",
    "\n",
    "Vale notar alguns detalhes sobre o código anterior:\n",
    "\n",
    " - o `DataLoader` de treinamento é criado com `train=True` e o de teste, com `train=False`, o que garante que não haja dados em comum entre os dois conjuntos;\n",
    " - `Nb` e `Nb_test` representam os tamanhos dos mini *batches* de treino e teste;\n",
    " - É feita a configuração de uma transformação de dados ao carregá-los. Para isso, é criado um objeto do tipo `transforms.Compose`, que permite encadear uma série de transformações a serem aplicadas às imagens, durante o carregamento. Nesse caso, a transformação tem uma única etapa que consistem em converter os valores obtidos para um tensor do PyTorch.\n",
    "\n",
    "Para ver algumas imagens do banco de dados usando o DataLoader criado, pode ser utilizado o seguinte código:\n",
    "\n",
    "``` python\n",
    "plt.figure(figsize=(16, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    plt.imshow(image.squeeze().numpy())\n",
    "    plt.axis('off');\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "\n",
    "Implemente uma rede MLP para classificação de imagens do conjunto Fashion MNIST usando o PyTorch. Lembre-se que trata-se de um problema de classificação multiclasse e utilize a arquitetura mais adequada.\n",
    "\n",
    "No caso de usar a entropia cruzada, vale notar que a função custo `CrossEntropyLoss` espera comparar um vetor de $C$ posições com um número de $0$ a $C-1$, conforme descrito na [documentação](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). Além disso, é esperado que os elementos do vetor representem a *evidência*, ou seja os valores chamados de *logits*, que não são normalizados e podem valer de $-\\infty$ a $\\infty$. Por isso, na saída da rede, não é usada a função *Softmax*.\n",
    "\n",
    "Por fim, avalie o modelo treinado em termos de acurácia (número de acertos dividido pelo número de testes) e busque variar os hiperparâmetros da rede a fim de obter uma acurácia próxima a 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
